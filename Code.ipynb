{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Scrape & Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 187 valid Greeklish sentences.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- Cleaner Functions ---\n",
    "def clean_text(text):\n",
    "    # Remove URLs, mentions, junk\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s.,!?]', '', text)  # Keep basic punctuation\n",
    "    return text.strip()\n",
    "\n",
    "def is_valid_greeklish(text):\n",
    "    text = clean_text(text.lower())\n",
    "    if len(text) < 3 or text in [\"[deleted]\", \"[removed]\"]:\n",
    "        return False\n",
    "    \n",
    "    # Reject Greek/Cyrillic scripts\n",
    "    if re.search(r'[α-ωά-ώΑ-Ω]', text) or re.search(r'[а-яА-Я]', text):\n",
    "        return False\n",
    "    \n",
    "    # Reject excessive numbers/leet (e.g., \"k4n315\")\n",
    "    if sum(c.isdigit() for c in text) > len(text) * 0.2:\n",
    "        return False\n",
    "    \n",
    "    # Key Greeklish words (customize as needed)\n",
    "    greeklish_words = {\n",
    "        \"kaneis\", \"einai\", \"thelw\", \"gia\", \"auto\", \"kai\", \"den\", \"ti\", \"mou\",\n",
    "        \"sou\", \"tora\", \"minymata\", \"ellinika\", \"greeklish\", \"vlepw\", \"kserw\"\n",
    "    }\n",
    "    words = set(re.findall(r'\\b\\w+\\b', text))\n",
    "    return len(words & greeklish_words) >= 2  # At least 2 Greeklish words\n",
    "\n",
    "# --- Reddit Scraper ---\n",
    "def scrape_reddit_greeklish():\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=\"X3Z5GcOruHvrwQLCPCoaVg\",\n",
    "        client_secret=\"XEZIOW5ckfnH37UT2mE-Yfad3HPRZg\",\n",
    "        user_agent=\"GreeklishScraper/0.0.1\",\n",
    "    )\n",
    "\n",
    "    posts = []\n",
    "    for submission in reddit.subreddit(\"greece\").search(\"greeklish\", limit=10000):\n",
    "        if is_valid_greeklish(submission.title):\n",
    "            posts.append({\"text\": submission.title, \"label\": \"greeklish\", \"source\": \"reddit\"})\n",
    "        \n",
    "        submission.comments.replace_more(limit=0)\n",
    "        for comment in submission.comments.list():\n",
    "            if is_valid_greeklish(comment.body):\n",
    "                posts.append({\"text\": comment.body, \"label\": \"greeklish\", \"source\": \"reddit\"})\n",
    "\n",
    "    df = pd.DataFrame(posts)\n",
    "    df.to_csv(\"greeklish_reddit_cleaned.csv\", index=False)\n",
    "    print(f\"Saved {len(df)} valid Greeklish sentences.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_reddit_greeklish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Greeklish samples: 187\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"greeklish_reddit_cleaned.csv\")\n",
    "print(f\"Total Greeklish samples: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 150 classic English sentences from Gutenberg.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_gutenberg():\n",
    "    # Pride and Prejudice - always available\n",
    "    url = \"https://www.gutenberg.org/files/1342/1342-0.txt\"  \n",
    "    response = requests.get(url)\n",
    "    text = response.text\n",
    "    \n",
    "    sentences = []\n",
    "    for sentence in re.split(r'(?<=[.!?])\\s+', text):\n",
    "        sentence = re.sub(r'[\\r\\n]+', ' ', sentence).strip()\n",
    "        if (8 < len(sentence.split()) < 25 and \n",
    "            sentence.isascii() and\n",
    "            not any(sentence.startswith(x) for x in [\"CHAPTER\", \"***\", \"[\"])):\n",
    "            sentences.append({\n",
    "                \"text\": sentence,\n",
    "                \"label\": \"english\",\n",
    "                \"source\": \"gutenberg\"\n",
    "            })\n",
    "            if len(sentences) >= 150:  # Get all needed samples from this reliable source\n",
    "                break\n",
    "    \n",
    "    pd.DataFrame(sentences).to_csv(\"english_gutenberg.csv\", index=False)\n",
    "    print(f\"Collected {len(sentences)} classic English sentences from Gutenberg.\")\n",
    "\n",
    "scrape_gutenberg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 150 English sentences from Wikipedia.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_wikipedia():\n",
    "    WIKI_URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "    sentences = []\n",
    "    \n",
    "    while len(sentences) < 150:\n",
    "        # Get random Wikipedia page\n",
    "        params = {\n",
    "            'action': 'query',\n",
    "            'format': 'json',\n",
    "            'list': 'random',\n",
    "            'rnnamespace': 0,\n",
    "            'rnlimit': 1\n",
    "        }\n",
    "        random_page = requests.get(WIKI_URL, params=params).json()\n",
    "        page_title = random_page['query']['random'][0]['title']\n",
    "        \n",
    "        # Get page content\n",
    "        params = {\n",
    "            'action': 'query',\n",
    "            'format': 'json',\n",
    "            'titles': page_title,\n",
    "            'prop': 'extracts',\n",
    "            'explaintext': True\n",
    "        }\n",
    "        page_content = requests.get(WIKI_URL, params=params).json()\n",
    "        text = next(iter(page_content['query']['pages'].values()))['extract']\n",
    "        \n",
    "        # Extract sentences\n",
    "        for sentence in re.split(r'(?<=[.!?])\\s+', text):\n",
    "            if 10 < len(sentence.split()) < 30 and sentence.isascii():\n",
    "                sentences.append({\n",
    "                    \"text\": sentence.strip(),\n",
    "                    \"label\": \"english\",\n",
    "                    \"source\": \"wikipedia\"\n",
    "                })\n",
    "                if len(sentences) >= 150:\n",
    "                    break\n",
    "    \n",
    "    pd.DataFrame(sentences).to_csv(\"english_wikipedia.csv\", index=False)\n",
    "    print(f\"Collected {len(sentences)} English sentences from Wikipedia.\")\n",
    "\n",
    "scrape_wikipedia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"greeklish_reddit_cleaned.csv\")\n",
    "df_gutenberg = pd.read_csv(\"english_gutenberg.csv\")\n",
    "df_wikipedia = pd.read_csv(\"english_wikipedia.csv\")\n",
    "df_combined = pd.concat([df, df_gutenberg, df_wikipedia], ignore_index=True)\n",
    "df_combined.to_csv(\"combined_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "729a23a8-8c88-4730-a292-04d7fa795512",
       "rows": [
        [
         "0",
         "den eixa ellinika sto kinito mou gia xronia kai akoma kai twra pou exw stelnw minymata se greeklish apo syni8eia. 8ymamai na einai 2003 kai na vlepw greeklish na xrisimopoiountai akomi kai sta forums. eixan ki afta tin plaka tous.\n\n  \nepisis, 8ym4741 k4n315 70 13375p34k? :D",
         "greeklish"
        ],
        [
         "1",
         "ir8a gia na dw ta sxolia sta greeklish",
         "greeklish"
        ],
        [
         "2",
         "gia na katastrepsw tin ellhnikh koultoura kai glwssa, na diaftheirw th neolaia kai na tous kanw olous na strepsoun tin plati tous makria apo tis patroparadotes paradoseis kai politismo\n\ni epeidi me volevei kai epeidi variemai na allaksw se ellhnika\n\ndialekse oti ap ta 2 thes",
         "greeklish"
        ],
        [
         "3",
         "Giati to turning point kata twn greeklish htan ena spot tou kanakh sthn thleorash. Den mou aresei oute o kanakhs oute h thleorash.",
         "greeklish"
        ],
        [
         "4",
         "Sinithos to Kano Gia nostalgikous logous me sigkekrimena atoma. Einai ena prama opos otan milao pontiaka me kana pontio.",
         "greeklish"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>den eixa ellinika sto kinito mou gia xronia ka...</td>\n",
       "      <td>greeklish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ir8a gia na dw ta sxolia sta greeklish</td>\n",
       "      <td>greeklish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gia na katastrepsw tin ellhnikh koultoura kai ...</td>\n",
       "      <td>greeklish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Giati to turning point kata twn greeklish htan...</td>\n",
       "      <td>greeklish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sinithos to Kano Gia nostalgikous logous me si...</td>\n",
       "      <td>greeklish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      label\n",
       "0  den eixa ellinika sto kinito mou gia xronia ka...  greeklish\n",
       "1             ir8a gia na dw ta sxolia sta greeklish  greeklish\n",
       "2  gia na katastrepsw tin ellhnikh koultoura kai ...  greeklish\n",
       "3  Giati to turning point kata twn greeklish htan...  greeklish\n",
       "4  Sinithos to Kano Gia nostalgikous logous me si...  greeklish"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.drop(columns=[\"source\"], inplace=True)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\debug\\miniconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\debug\\miniconda3\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\debug\\miniconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\debug\\miniconda3\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\debug\\miniconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\debug\\miniconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Saved dataset with sentences as 'sentences_dataset.csv'.\n",
      "                                                text      label\n",
      "0  den eixa ellinika sto kinito mou gia xronia ka...  greeklish\n",
      "1  8ymamai na einai 2003 kai na vlepw greeklish n...  greeklish\n",
      "2                      eixan ki afta tin plaka tous.  greeklish\n",
      "3               episis, 8ym4741 k4n315 70 13375p34k?  greeklish\n",
      "4                                                 :D  greeklish\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Download the sentence tokenizer (only needed once)\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "# Function to split paragraphs into sentences\n",
    "def split_paragraphs_to_sentences(df, text_column):\n",
    "    expanded_rows = []  # Store sentence-level rows\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sentences = sent_tokenize(str(row[text_column]))  # Tokenize sentences\n",
    "        for sentence in sentences:\n",
    "            expanded_rows.append({text_column: sentence, 'label': row['label']})\n",
    "\n",
    "    return pd.DataFrame(expanded_rows)  # Create new DataFrame\n",
    "\n",
    "# Apply sentence splitting\n",
    "df_sentences = split_paragraphs_to_sentences(df_combined, 'text')\n",
    "\n",
    "# Save the new dataset\n",
    "df_sentences.to_csv(\"sentences_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Saved dataset with sentences as 'sentences_dataset.csv'.\")\n",
    "print(df_sentences.head())  # Show first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(728, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data preview:\n",
      "                                                text      label\n",
      "0  den eixa ellinika sto kinito mou gia xronia ka...  greeklish\n",
      "1  8ymamai na einai 2003 kai na vlepw greeklish n...  greeklish\n",
      "2                      eixan ki afta tin plaka tous.  greeklish\n",
      "3               episis, 8ym4741 k4n315 70 13375p34k?  greeklish\n",
      "4                                                 :D  greeklish\n",
      "Total sentences: 728\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "df = pd.read_csv('sentences_dataset.csv') \n",
    "print(\"Initial data preview:\")\n",
    "print(df.head())\n",
    "print(f\"Total sentences: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "import re\n",
    "from time import sleep\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC  # Changed from LogisticRegression to SVM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from google.colab import files\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Preprocessing function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Remove punctuation\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning\n",
    "df['text'] = df['text'].astype(str).apply(clean_text)\n",
    "df.dropna(subset=['text'], inplace=True)  # Remove NaN sentences\n",
    "df.drop_duplicates(subset=['text'], inplace=True)  # Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TF-IDF + SVM pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 3), analyzer='char')),  # Character-level TF-IDF\n",
    "    ('svm', SVC(kernel='rbf', probability=True))  # SVM with RBF kernel\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 3))),\n",
       "                (&#x27;svm&#x27;, SVC(probability=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 3))),\n",
       "                (&#x27;svm&#x27;, SVC(probability=True))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 3))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(probability=True)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(analyzer='char', ngram_range=(1, 3))),\n",
       "                ('svm', SVC(probability=True))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train model\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=\"greeklish\")\n",
    "recall = recall_score(y_test, y_pred, pos_label=\"greeklish\")\n",
    "f1 = f1_score(y_test, y_pred, pos_label=\"greeklish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9953\n",
      "Precision: 1.0000\n",
      "Recall: 0.9920\n",
      "F1-score: 0.9960\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model saved as 'greeklish_svm_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "joblib.dump(pipeline, \"greeklish_svm_model.pkl\")\n",
    "print(\"SVM model saved as 'greeklish_svm_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greeklish\n",
      "english\n"
     ]
    }
   ],
   "source": [
    "# Load saved model\n",
    "model = joblib.load(\"greeklish_svm_model.pkl\")\n",
    "\n",
    "# Function to classify new text\n",
    "def predict_text(text):\n",
    "    processed_text = clean_text(text)\n",
    "    prediction = model.predict([processed_text])[0]\n",
    "    return prediction\n",
    "\n",
    "# Test examples\n",
    "print(predict_text(\"ti kaneis\"))  # Expected: Greeklish\n",
    "print(predict_text(\"Hello, how are you?\"))  # Expected: English\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
